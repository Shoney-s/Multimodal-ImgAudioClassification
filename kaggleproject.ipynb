{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport random\nimport os\n\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:18.225900Z","iopub.execute_input":"2021-05-28T20:10:18.226256Z","iopub.status.idle":"2021-05-28T20:10:18.230943Z","shell.execute_reply.started":"2021-05-28T20:10:18.226218Z","shell.execute_reply":"2021-05-28T20:10:18.230028Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"markdown","source":"**Context**\n\nKaggle dataset lien https://www.kaggle.com/birdy654/scene-classification-images-and-audio","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/scene-classification-images-and-audio/dataset.csv', delimiter=',', nrows=None)\ndata_train = np.array(data)\n\naudio = data_train[:,1:-2].astype('float32') #last index of the interval isn't included in the range : CLASS1\nlabels = data_train[:,-1]\nimg_paths = data['IMAGE']\n\nclasses = [\"FOREST\", \"CLASSROOM\", \"CITY\", \"RIVER\", \"GROCERY-STORE\",\"JUNGLE\",\"BEACH\",\"FOOTBALL-MATCH\",\"RESTAURANT\"]\nfor index,class_name in enumerate(classes):\n    labels = np.where(labels == class_name, index, labels)\n\nlabels.astype('int32')\n\ndata.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:18.235635Z","iopub.execute_input":"2021-05-28T20:10:18.236034Z","iopub.status.idle":"2021-05-28T20:10:18.896660Z","shell.execute_reply.started":"2021-05-28T20:10:18.235954Z","shell.execute_reply":"2021-05-28T20:10:18.895720Z"},"trusted":true},"execution_count":201,"outputs":[{"execution_count":201,"output_type":"execute_result","data":{"text/plain":"                       IMAGE     mfcc_1     mfcc_2     mfcc_3     mfcc_4  \\\n0  images/forest/forest0.png  15.795384  -3.442518 -25.316836 -33.412104   \n1  images/forest/forest1.png  15.883880  -3.494075 -21.189490 -18.077115   \n2  images/forest/forest2.png  17.872629 -18.877467 -31.665319 -47.045579   \n3  images/forest/forest3.png  16.843997  -3.527753 -21.282970 -24.248141   \n4  images/forest/forest4.png  16.128583  -4.267328 -25.608325 -20.231084   \n\n      mfcc_5     mfcc_6     mfcc_7     mfcc_8     mfcc_9  ...    mfcc_97  \\\n0   2.447290 -46.981182  12.889984 -23.588534 -22.625879  ... -43.876462   \n1   4.284962 -27.014271   3.666955  -9.091312  -3.746509  ... -33.883092   \n2   1.813430 -45.899877  14.975982 -24.462396  -1.812962  ... -34.456028   \n3  27.201589 -18.787674  30.093938  -1.922008  10.156418  ... -36.410615   \n4  15.922823 -35.703313  16.307644  -3.547505   4.804142  ... -41.548915   \n\n     mfcc_98    mfcc_99   mfcc_100   mfcc_101   mfcc_102   mfcc_103  \\\n0  20.697491 -22.793173  -9.417196  13.762870 -31.976786  18.461561   \n1  17.223236 -24.985005  12.035913   8.321000 -16.249293   8.717523   \n2  21.433239 -14.190274  -8.629235   1.035640 -20.703358   5.986662   \n3  19.949251  -5.466172   6.480569  13.070739 -14.853299  10.243606   \n4  15.697646 -20.615005 -11.942869   5.421639 -27.445147   9.060233   \n\n    mfcc_104    CLASS1  CLASS2  \n0 -13.140673  OUTDOORS  FOREST  \n1   0.743640  OUTDOORS  FOREST  \n2 -14.644013  OUTDOORS  FOREST  \n3 -17.983957  OUTDOORS  FOREST  \n4 -15.077528  OUTDOORS  FOREST  \n\n[5 rows x 107 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMAGE</th>\n      <th>mfcc_1</th>\n      <th>mfcc_2</th>\n      <th>mfcc_3</th>\n      <th>mfcc_4</th>\n      <th>mfcc_5</th>\n      <th>mfcc_6</th>\n      <th>mfcc_7</th>\n      <th>mfcc_8</th>\n      <th>mfcc_9</th>\n      <th>...</th>\n      <th>mfcc_97</th>\n      <th>mfcc_98</th>\n      <th>mfcc_99</th>\n      <th>mfcc_100</th>\n      <th>mfcc_101</th>\n      <th>mfcc_102</th>\n      <th>mfcc_103</th>\n      <th>mfcc_104</th>\n      <th>CLASS1</th>\n      <th>CLASS2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>images/forest/forest0.png</td>\n      <td>15.795384</td>\n      <td>-3.442518</td>\n      <td>-25.316836</td>\n      <td>-33.412104</td>\n      <td>2.447290</td>\n      <td>-46.981182</td>\n      <td>12.889984</td>\n      <td>-23.588534</td>\n      <td>-22.625879</td>\n      <td>...</td>\n      <td>-43.876462</td>\n      <td>20.697491</td>\n      <td>-22.793173</td>\n      <td>-9.417196</td>\n      <td>13.762870</td>\n      <td>-31.976786</td>\n      <td>18.461561</td>\n      <td>-13.140673</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>images/forest/forest1.png</td>\n      <td>15.883880</td>\n      <td>-3.494075</td>\n      <td>-21.189490</td>\n      <td>-18.077115</td>\n      <td>4.284962</td>\n      <td>-27.014271</td>\n      <td>3.666955</td>\n      <td>-9.091312</td>\n      <td>-3.746509</td>\n      <td>...</td>\n      <td>-33.883092</td>\n      <td>17.223236</td>\n      <td>-24.985005</td>\n      <td>12.035913</td>\n      <td>8.321000</td>\n      <td>-16.249293</td>\n      <td>8.717523</td>\n      <td>0.743640</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>images/forest/forest2.png</td>\n      <td>17.872629</td>\n      <td>-18.877467</td>\n      <td>-31.665319</td>\n      <td>-47.045579</td>\n      <td>1.813430</td>\n      <td>-45.899877</td>\n      <td>14.975982</td>\n      <td>-24.462396</td>\n      <td>-1.812962</td>\n      <td>...</td>\n      <td>-34.456028</td>\n      <td>21.433239</td>\n      <td>-14.190274</td>\n      <td>-8.629235</td>\n      <td>1.035640</td>\n      <td>-20.703358</td>\n      <td>5.986662</td>\n      <td>-14.644013</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>images/forest/forest3.png</td>\n      <td>16.843997</td>\n      <td>-3.527753</td>\n      <td>-21.282970</td>\n      <td>-24.248141</td>\n      <td>27.201589</td>\n      <td>-18.787674</td>\n      <td>30.093938</td>\n      <td>-1.922008</td>\n      <td>10.156418</td>\n      <td>...</td>\n      <td>-36.410615</td>\n      <td>19.949251</td>\n      <td>-5.466172</td>\n      <td>6.480569</td>\n      <td>13.070739</td>\n      <td>-14.853299</td>\n      <td>10.243606</td>\n      <td>-17.983957</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>images/forest/forest4.png</td>\n      <td>16.128583</td>\n      <td>-4.267328</td>\n      <td>-25.608325</td>\n      <td>-20.231084</td>\n      <td>15.922823</td>\n      <td>-35.703313</td>\n      <td>16.307644</td>\n      <td>-3.547505</td>\n      <td>4.804142</td>\n      <td>...</td>\n      <td>-41.548915</td>\n      <td>15.697646</td>\n      <td>-20.615005</td>\n      <td>-11.942869</td>\n      <td>5.421639</td>\n      <td>-27.445147</td>\n      <td>9.060233</td>\n      <td>-15.077528</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 107 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"img_train, img_temp, audio_train, audio_temp, labels_train, labels_temp = train_test_split(img_paths, audio, labels, train_size=0.6)\nimg_val, img_test, audio_val, audio_test, labels_val, labels_test = train_test_split(img_temp, audio_temp, labels_temp, train_size=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:18.898238Z","iopub.execute_input":"2021-05-28T20:10:18.898584Z","iopub.status.idle":"2021-05-28T20:10:18.915431Z","shell.execute_reply.started":"2021-05-28T20:10:18.898548Z","shell.execute_reply":"2021-05-28T20:10:18.914613Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"markdown","source":"On définit les seeds qui permettent de générer aléatoirement les mêmes nombres, et donc rendre les résultats reproductibles.","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(0)\ntorch.cuda.manual_seed_all(0)\nrandom.seed(0)\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:18.917182Z","iopub.execute_input":"2021-05-28T20:10:18.917523Z","iopub.status.idle":"2021-05-28T20:10:18.922053Z","shell.execute_reply.started":"2021-05-28T20:10:18.917487Z","shell.execute_reply":"2021-05-28T20:10:18.921043Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"markdown","source":"**Pytorch Dataset**\n\nOn créé une classe Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\n\nclass CustomDataset(Dataset):\n    def __init__(self, root_dir, img_data, audio_data, labels=None, img_transform=None, audio_transform=None):\n        self.root_dir = root_dir\n        self.img_data = img_data\n        self.audio_data = audio_data\n        self.labels = labels\n        self.img_transform = img_transform\n        self.audio_transform = audio_transform\n        \n    def __len__(self):\n        return len(self.img_data)\n        \n    def __getitem__(self, idx):\n        img = Image.open(os.path.join(self.root_dir, self.img_data.iloc[idx]))\n        audio = self.audio_data[idx,:]\n        if self.img_transform:\n            img = self.img_transform(img)\n        if self.audio_transform:\n            audio = self.audio_transform(audio)        \n                               \n        return ((img, audio) if labels is None else (img, audio, int(self.labels[idx])))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:18.923875Z","iopub.execute_input":"2021-05-28T20:10:18.924258Z","iopub.status.idle":"2021-05-28T20:10:18.934445Z","shell.execute_reply.started":"2021-05-28T20:10:18.924221Z","shell.execute_reply":"2021-05-28T20:10:18.933559Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"markdown","source":"**TRAIN**","metadata":{}},{"cell_type":"code","source":"def train(data_type, model, train_loader, val_loader, criterion, optimizer, scheduler, epochs):\n    \n    i = 1\n    for epoch in range(epochs):\n        print(\"epoch : \" + str(i))\n        i+=1\n        running_loss = 0.0\n        running_corrects = 0.0\n        epoch_loss_sum = 0.0\n        epoch_loss = 0.0\n        epoch_acc = 0.0\n        for index, data in enumerate(train_loader):\n            img, audio, labels = data\n            img, audio, labels = img.cuda(), audio.cuda(), labels.cuda()\n            \n            optimizer.zero_grad()\n            \n            # forward\n            if data_type == \"img\":\n                outputs = model(img)\n            elif data_type == \"audio\":\n                outputs = model(audio)\n            elif data_type == \"imgaudio\":\n                outputs = model(img, audio)\n            else:\n                raise ValueError('Data must be img, audio or imgaudio')\n            \n            loss = criterion(outputs,labels) # compare obtained and expected output\n            _, preds = torch.max(outputs, 1)\n            loss.backward() # backward\n            optimizer.step() # compute gradient for optimization\n            \n            #print statistics\n            running_loss += loss.item()\n            \n            if index % 200 == 199:    \n                print('[%d, %5d] loss: %.3f' % (epoch + 1, index + 1, running_loss / 200))\n                running_loss = 0.0\n                \n            running_corrects += torch.sum(preds == labels.data)\n            epoch_loss_sum += loss.item()\n            \n        epoch_loss = epoch_loss_sum / len(train_loader)\n        epoch_acc = running_corrects / len(train_loader)\n            \n    #return model, loss_vals, train_acc_vals\n        \"\"\"\n            #We compute validation data accuracy on each epoch to prevent overfitting \n            #if val_accuracy isn't improved by current training epoch\n            val_acc = 0\n            model.eval()\n            with torch.no_grad: #Validation data aim to test, not to train NN --> grad isn't needed\n                for img, audio, labels in val_loader:\n                    img, audio, labels = img.cuda(), audio.cuda(), labels.cuda()\n                    if data_type == \"img\":\n                        outputs = model(img)\n                    elif data_type == \"audio\":\n                        outputs = model(audio)\n                    else:\n                        outputs = model(img, audio)\n                        \"\"\"\n    return None","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:18.935691Z","iopub.execute_input":"2021-05-28T20:10:18.936249Z","iopub.status.idle":"2021-05-28T20:10:18.948295Z","shell.execute_reply.started":"2021-05-28T20:10:18.936215Z","shell.execute_reply":"2021-05-28T20:10:18.947416Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"markdown","source":"**PREDICT**","metadata":{}},{"cell_type":"code","source":"def predict(test_loader, model):\n    model.eval()\n    \n    with torch.no_grad: #Validation data aim to test, not to train NN --> grad isn't needed\n        for data_type, img, audio, labels in test_loader:\n            img, audio = img.cuda(), audio.cuda()\n        if data_type == \"img\":\n            outputs = model(img)\n        elif data_type == \"audio\":\n            outputs = model(audio)\n        else:\n             outputs = model(img, audio)\n                \n    return None","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:18.949571Z","iopub.execute_input":"2021-05-28T20:10:18.950020Z","iopub.status.idle":"2021-05-28T20:10:18.958986Z","shell.execute_reply.started":"2021-05-28T20:10:18.949976Z","shell.execute_reply":"2021-05-28T20:10:18.958280Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"markdown","source":"**<font size=\"6\" color=\"darkblue\">IMAGES</font>**\n\nExplication données image","metadata":{}},{"cell_type":"markdown","source":"**IMAGE VISUALIZATION**","metadata":{}},{"cell_type":"markdown","source":"**DATA TRANSFORMATION** ","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\n# DA : Data Augmentation\n# DP : Data Preparation --> transform data to a more ergonomic data format\n\nimg_train_transform = transforms.Compose([ #Compose is used to chain multiple transforms to create a transformation pipeline\n    transforms.RandomResizedCrop(224), #DA\n    transforms.RandomHorizontalFlip(), #DA\n    transforms.ToTensor(), #DP to compute on GPU\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) #DP\n])\nimg_val_transform = transforms.Compose([\n    transforms.Resize(256), #DA fixed resize and crop for reliability\n    transforms.CenterCrop(224),# DA\n    transforms.ToTensor(), #DP\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) #DP\n])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:18.960286Z","iopub.execute_input":"2021-05-28T20:10:18.960731Z","iopub.status.idle":"2021-05-28T20:10:18.968401Z","shell.execute_reply.started":"2021-05-28T20:10:18.960697Z","shell.execute_reply":"2021-05-28T20:10:18.967681Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"markdown","source":"**IMAGE LOADER**","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\ntrain_data = CustomDataset(root_dir='/kaggle/input/scene-classification-images-and-audio', img_data=img_train, audio_data=audio_train, labels=labels_train, img_transform=img_train_transform)\nval_data = CustomDataset(root_dir='/kaggle/input/scene-classification-images-and-audio/', img_data=img_val,  audio_data=audio_val,labels=labels_val, img_transform=img_val_transform)\n\ntrain_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_data, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:18.971407Z","iopub.execute_input":"2021-05-28T20:10:18.971716Z","iopub.status.idle":"2021-05-28T20:10:18.980249Z","shell.execute_reply.started":"2021-05-28T20:10:18.971659Z","shell.execute_reply":"2021-05-28T20:10:18.979481Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"markdown","source":"**TRANSFER LEARNING** \n\non charge le réseau préentrainé\nOn utilise Imagenet","metadata":{}},{"cell_type":"code","source":"import torchvision.models\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nresnext = torchvision.models.resnext50_32x4d(pretrained=True, progress=True)\n\nfor param in resnext.parameters():\n    param.requires_grad = False\n    \nnum_ftrs = resnext.fc.in_features\nresnext.fc = nn.Linear(num_ftrs, 9)\n\nresnext = resnext.cuda()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-05-28T20:10:18.981897Z","iopub.execute_input":"2021-05-28T20:10:18.982262Z","iopub.status.idle":"2021-05-28T20:10:19.505987Z","shell.execute_reply.started":"2021-05-28T20:10:18.982229Z","shell.execute_reply":"2021-05-28T20:10:19.505171Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"from torch.optim import lr_scheduler\nimport torch.optim as optim\n\noptimizer = optim.Adam(resnext.fc.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=0,factor=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:19.507308Z","iopub.execute_input":"2021-05-28T20:10:19.507649Z","iopub.status.idle":"2021-05-28T20:10:19.514737Z","shell.execute_reply.started":"2021-05-28T20:10:19.507614Z","shell.execute_reply":"2021-05-28T20:10:19.513903Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nepochs = 10\ndata_type = 'img'\nresnext, loss_vals, train_acc_vals, val_acc_vals = train(data_type, resnext, train_loader, val_loader, criterion, optimizer, scheduler, epochs)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:10:19.517056Z","iopub.execute_input":"2021-05-28T20:10:19.517706Z","iopub.status.idle":"2021-05-28T20:19:45.632396Z","shell.execute_reply.started":"2021-05-28T20:10:19.517669Z","shell.execute_reply":"2021-05-28T20:19:45.630520Z"},"trusted":true},"execution_count":211,"outputs":[{"name":"stdout","text":"epoch : 1\n[1,   200] loss: 0.693\n[1,   400] loss: 0.325\n[1,   600] loss: 0.262\nepoch : 2\n[2,   200] loss: 0.233\n[2,   400] loss: 0.217\n[2,   600] loss: 0.217\nepoch : 3\n[3,   200] loss: 0.200\n[3,   400] loss: 0.190\n[3,   600] loss: 0.182\nepoch : 4\n[4,   200] loss: 0.202\n[4,   400] loss: 0.190\n[4,   600] loss: 0.180\nepoch : 5\n[5,   200] loss: 0.191\n[5,   400] loss: 0.178\n[5,   600] loss: 0.167\nepoch : 6\n[6,   200] loss: 0.165\n[6,   400] loss: 0.143\n[6,   600] loss: 0.162\nepoch : 7\n[7,   200] loss: 0.163\n[7,   400] loss: 0.147\n[7,   600] loss: 0.161\nepoch : 8\n[8,   200] loss: 0.156\n[8,   400] loss: 0.151\n[8,   600] loss: 0.157\nepoch : 9\n[9,   200] loss: 0.155\n[9,   400] loss: 0.161\n[9,   600] loss: 0.149\nepoch : 10\n[10,   200] loss: 0.132\n[10,   400] loss: 0.178\n[10,   600] loss: 0.150\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-211-80834046b680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'img'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"],"ename":"TypeError","evalue":"cannot unpack non-iterable NoneType object","output_type":"error"}]},{"cell_type":"markdown","source":"**<font size=\"6\" color=\"darkblue\">AUDIO</font>**\n\nType de données MCCF","metadata":{}},{"cell_type":"markdown","source":"**AUDIO DATA VISUALIZATION**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.subplot(2,2,1)\nplt.hist(audio[::,0])\nplt.title('mfcc_1')\nplt.subplot(2,2,2)\nplt.hist(audio[::,1])\nplt.title('mfcc_2')\nplt.subplot(2,2,3)\nplt.hist(audio[::,2])\nplt.title('mfcc_3')\nplt.subplot(2,2,4)\nplt.hist(audio[::,3])\nplt.title('mfcc_4')\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:43:21.740544Z","iopub.execute_input":"2021-05-28T20:43:21.740908Z","iopub.status.idle":"2021-05-28T20:43:42.397893Z","shell.execute_reply.started":"2021-05-28T20:43:21.740868Z","shell.execute_reply":"2021-05-28T20:43:42.397018Z"},"trusted":true},"execution_count":241,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 4 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self):\n        super(MLP, self).__init__()\n        \n        self.linear1 = nn.Linear(104, 156)\n        self.bn1 = nn.BatchNorm1d(156)\n        \n        self.linear2 = nn.Linear(156, 208)\n        self.bn2 = nn.BatchNorm1d(208)\n        \n        self.linear3 = nn.Linear(208, 156)\n        self.bn3 = nn.BatchNorm1d(156)\n        \n        self.linear4 = nn.Linear(156, 104)\n        self.bn4 = nn.BatchNorm1d(104)\n        \n        self.linear5 = nn.Linear(104, 64)\n        self.bn5 = nn.BatchNorm1d(64)\n\n\n        self.final = nn.Linear(64,9)\n      \n    def forward(self, x):\n        x = F.leaky_relu(self.bn1(self.linear1(x)))\n        x = F.leaky_relu(self.bn2(self.linear2(x)))\n        x = F.leaky_relu(self.bn3(self.linear3(x)))\n        x = F.leaky_relu(self.bn4(self.linear4(x)))\n        x = F.leaky_relu(self.bn5(self.linear5(x)))\n\n        x = self.final(x)\n        return x\n\nmlp = MLP().cuda()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:43:42.399338Z","iopub.execute_input":"2021-05-28T20:43:42.399614Z","iopub.status.idle":"2021-05-28T20:43:42.416558Z","shell.execute_reply.started":"2021-05-28T20:43:42.399586Z","shell.execute_reply":"2021-05-28T20:43:42.415746Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"markdown","source":"**DATA PROCESSING METHODS**","metadata":{}},{"cell_type":"code","source":"def normalize(data):\n    return (data - np.mean(data, axis=0))/np.std(data, axis=0)\n\naudio_train = normalize(audio_train)\naudio_val = normalize(audio_val)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:48:49.577262Z","iopub.execute_input":"2021-05-28T20:48:49.577614Z","iopub.status.idle":"2021-05-28T20:48:49.597176Z","shell.execute_reply.started":"2021-05-28T20:48:49.577579Z","shell.execute_reply":"2021-05-28T20:48:49.596389Z"},"trusted":true},"execution_count":254,"outputs":[]},{"cell_type":"code","source":"class AddGaussianNoise:\n    def __init__(self, mean=0., std=1.):\n        self.std = std\n        self.mean = mean\n        \n    def __call__(self, tensor):\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n    \n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:48:50.101789Z","iopub.execute_input":"2021-05-28T20:48:50.102113Z","iopub.status.idle":"2021-05-28T20:48:50.109398Z","shell.execute_reply.started":"2021-05-28T20:48:50.102081Z","shell.execute_reply":"2021-05-28T20:48:50.107394Z"},"trusted":true},"execution_count":255,"outputs":[]},{"cell_type":"code","source":"class RandomCircularShift:      \n    def __call__(self, tensor):\n        return torch.roll(tensor, 13*np.random.randint(8),dims=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:48:51.115025Z","iopub.execute_input":"2021-05-28T20:48:51.115384Z","iopub.status.idle":"2021-05-28T20:48:51.120023Z","shell.execute_reply.started":"2021-05-28T20:48:51.115350Z","shell.execute_reply":"2021-05-28T20:48:51.119018Z"},"trusted":true},"execution_count":256,"outputs":[]},{"cell_type":"markdown","source":"**AUDIO DATA TRANSFORMATION** ","metadata":{}},{"cell_type":"code","source":"img_train_transform = transforms.Compose([ #Compose is used to chain multiple transforms to create a transformation pipeline\n    transforms.RandomResizedCrop(224), #DA\n    transforms.RandomHorizontalFlip(), #DA\n    transforms.ToTensor(), #DP to compute on GPU\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) #DP\n])\nimg_val_transform = transforms.Compose([\n    transforms.Resize(256), #DA fixed resize and crop for reliability\n    transforms.CenterCrop(224),# DA\n    transforms.ToTensor(), #DP\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) #DP\n])\n\naudio_train_transform = transforms.Compose([\n    torch.from_numpy,\n    AddGaussianNoise(0.0, 0.1),\n    RandomCircularShift()\n])\n\naudio_val_transform = transforms.Compose([\n    AddGaussianNoise(0.0, 0.1),\n    RandomCircularShift()\n])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:48:52.709660Z","iopub.execute_input":"2021-05-28T20:48:52.709980Z","iopub.status.idle":"2021-05-28T20:48:52.717603Z","shell.execute_reply.started":"2021-05-28T20:48:52.709950Z","shell.execute_reply":"2021-05-28T20:48:52.716460Z"},"trusted":true},"execution_count":257,"outputs":[]},{"cell_type":"markdown","source":"**AUDIO DATA LOADER**","metadata":{}},{"cell_type":"code","source":"train_data = CustomDataset(root_dir='/kaggle/input/scene-classification-images-and-audio', img_data=img_train, audio_data=audio_train, labels=labels_train, img_transform = img_train_transform, audio_transform=audio_train_transform)\nval_data = CustomDataset(root_dir='/kaggle/input/scene-classification-images-and-audio4', img_data=img_val, audio_data=audio_val, labels=labels_val, img_transform = img_val_transform, audio_transform=audio_val_transform)\n\ntrain_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_data, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:48:54.161537Z","iopub.execute_input":"2021-05-28T20:48:54.161853Z","iopub.status.idle":"2021-05-28T20:48:54.168794Z","shell.execute_reply.started":"2021-05-28T20:48:54.161826Z","shell.execute_reply":"2021-05-28T20:48:54.166912Z"},"trusted":true},"execution_count":258,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(resnext.fc.parameters(), lr=0.001) \ncriterion = nn.CrossEntropyLoss()\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=0,factor=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:48:54.988107Z","iopub.execute_input":"2021-05-28T20:48:54.988473Z","iopub.status.idle":"2021-05-28T20:48:54.993112Z","shell.execute_reply.started":"2021-05-28T20:48:54.988441Z","shell.execute_reply":"2021-05-28T20:48:54.992246Z"},"trusted":true},"execution_count":259,"outputs":[]},{"cell_type":"code","source":"epochs = 10\ndata_type = 'audio'\nresnext, loss_vals, train_acc_vals, val_acc_vals = train(data_type, mlp, train_loader, val_loader, criterion, optimizer, scheduler, epochs)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T20:51:20.621331Z","iopub.execute_input":"2021-05-28T20:51:20.621665Z","iopub.status.idle":"2021-05-28T20:59:00.150982Z","shell.execute_reply.started":"2021-05-28T20:51:20.621635Z","shell.execute_reply":"2021-05-28T20:59:00.149021Z"},"trusted":true},"execution_count":262,"outputs":[{"name":"stdout","text":"epoch : 1\n[1,   200] loss: 2.199\n[1,   400] loss: 2.199\n[1,   600] loss: 2.207\nepoch : 2\n[2,   200] loss: 2.196\n[2,   400] loss: 2.208\n[2,   600] loss: 2.220\nepoch : 3\n[3,   200] loss: 2.198\n[3,   400] loss: 2.204\n[3,   600] loss: 2.201\nepoch : 4\n[4,   200] loss: 2.203\n[4,   400] loss: 2.206\n[4,   600] loss: 2.201\nepoch : 5\n[5,   200] loss: 2.209\n[5,   400] loss: 2.200\n[5,   600] loss: 2.206\nepoch : 6\n[6,   200] loss: 2.204\n[6,   400] loss: 2.207\n[6,   600] loss: 2.200\nepoch : 7\n[7,   200] loss: 2.194\n[7,   400] loss: 2.216\n[7,   600] loss: 2.202\nepoch : 8\n[8,   200] loss: 2.216\n[8,   400] loss: 2.207\n[8,   600] loss: 2.206\nepoch : 9\n[9,   200] loss: 2.203\n[9,   400] loss: 2.190\n[9,   600] loss: 2.206\nepoch : 10\n[10,   200] loss: 2.198\n[10,   400] loss: 2.207\n[10,   600] loss: 2.201\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-262-0a9c957eed6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'audio'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"],"ename":"TypeError","evalue":"cannot unpack non-iterable NoneType object","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}