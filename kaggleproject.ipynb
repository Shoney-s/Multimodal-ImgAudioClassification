{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context**\n",
    "\n",
    "Kaggle dataset lien https://www.kaggle.com/birdy654/scene-classification-images-and-audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10351, 104)\n",
      "(3450, 104)\n",
      "(3451, 104)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMAGE</th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_97</th>\n",
       "      <th>mfcc_98</th>\n",
       "      <th>mfcc_99</th>\n",
       "      <th>mfcc_100</th>\n",
       "      <th>mfcc_101</th>\n",
       "      <th>mfcc_102</th>\n",
       "      <th>mfcc_103</th>\n",
       "      <th>mfcc_104</th>\n",
       "      <th>CLASS1</th>\n",
       "      <th>CLASS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/forest/forest0.png</td>\n",
       "      <td>15.795384</td>\n",
       "      <td>-3.442518</td>\n",
       "      <td>-25.316836</td>\n",
       "      <td>-33.412104</td>\n",
       "      <td>2.447290</td>\n",
       "      <td>-46.981182</td>\n",
       "      <td>12.889984</td>\n",
       "      <td>-23.588534</td>\n",
       "      <td>-22.625879</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.876462</td>\n",
       "      <td>20.697491</td>\n",
       "      <td>-22.793173</td>\n",
       "      <td>-9.417196</td>\n",
       "      <td>13.762870</td>\n",
       "      <td>-31.976786</td>\n",
       "      <td>18.461561</td>\n",
       "      <td>-13.140673</td>\n",
       "      <td>OUTDOORS</td>\n",
       "      <td>FOREST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/forest/forest1.png</td>\n",
       "      <td>15.883880</td>\n",
       "      <td>-3.494075</td>\n",
       "      <td>-21.189490</td>\n",
       "      <td>-18.077115</td>\n",
       "      <td>4.284962</td>\n",
       "      <td>-27.014271</td>\n",
       "      <td>3.666955</td>\n",
       "      <td>-9.091312</td>\n",
       "      <td>-3.746509</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.883092</td>\n",
       "      <td>17.223236</td>\n",
       "      <td>-24.985005</td>\n",
       "      <td>12.035913</td>\n",
       "      <td>8.321000</td>\n",
       "      <td>-16.249293</td>\n",
       "      <td>8.717523</td>\n",
       "      <td>0.743640</td>\n",
       "      <td>OUTDOORS</td>\n",
       "      <td>FOREST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/forest/forest2.png</td>\n",
       "      <td>17.872629</td>\n",
       "      <td>-18.877467</td>\n",
       "      <td>-31.665319</td>\n",
       "      <td>-47.045579</td>\n",
       "      <td>1.813430</td>\n",
       "      <td>-45.899877</td>\n",
       "      <td>14.975982</td>\n",
       "      <td>-24.462396</td>\n",
       "      <td>-1.812962</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.456028</td>\n",
       "      <td>21.433239</td>\n",
       "      <td>-14.190274</td>\n",
       "      <td>-8.629235</td>\n",
       "      <td>1.035640</td>\n",
       "      <td>-20.703358</td>\n",
       "      <td>5.986662</td>\n",
       "      <td>-14.644013</td>\n",
       "      <td>OUTDOORS</td>\n",
       "      <td>FOREST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/forest/forest3.png</td>\n",
       "      <td>16.843997</td>\n",
       "      <td>-3.527753</td>\n",
       "      <td>-21.282970</td>\n",
       "      <td>-24.248141</td>\n",
       "      <td>27.201589</td>\n",
       "      <td>-18.787674</td>\n",
       "      <td>30.093938</td>\n",
       "      <td>-1.922008</td>\n",
       "      <td>10.156418</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.410615</td>\n",
       "      <td>19.949251</td>\n",
       "      <td>-5.466172</td>\n",
       "      <td>6.480569</td>\n",
       "      <td>13.070739</td>\n",
       "      <td>-14.853299</td>\n",
       "      <td>10.243606</td>\n",
       "      <td>-17.983957</td>\n",
       "      <td>OUTDOORS</td>\n",
       "      <td>FOREST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/forest/forest4.png</td>\n",
       "      <td>16.128583</td>\n",
       "      <td>-4.267328</td>\n",
       "      <td>-25.608325</td>\n",
       "      <td>-20.231084</td>\n",
       "      <td>15.922823</td>\n",
       "      <td>-35.703313</td>\n",
       "      <td>16.307644</td>\n",
       "      <td>-3.547505</td>\n",
       "      <td>4.804142</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.548915</td>\n",
       "      <td>15.697646</td>\n",
       "      <td>-20.615005</td>\n",
       "      <td>-11.942869</td>\n",
       "      <td>5.421639</td>\n",
       "      <td>-27.445147</td>\n",
       "      <td>9.060233</td>\n",
       "      <td>-15.077528</td>\n",
       "      <td>OUTDOORS</td>\n",
       "      <td>FOREST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>images/forest/forest5.png</td>\n",
       "      <td>21.689841</td>\n",
       "      <td>-15.971450</td>\n",
       "      <td>-26.837817</td>\n",
       "      <td>-46.561006</td>\n",
       "      <td>20.770073</td>\n",
       "      <td>-8.153000</td>\n",
       "      <td>16.801556</td>\n",
       "      <td>-4.589764</td>\n",
       "      <td>7.219863</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.613514</td>\n",
       "      <td>42.223289</td>\n",
       "      <td>-11.695203</td>\n",
       "      <td>2.910106</td>\n",
       "      <td>-35.891702</td>\n",
       "      <td>-2.755247</td>\n",
       "      <td>-2.448610</td>\n",
       "      <td>13.279929</td>\n",
       "      <td>OUTDOORS</td>\n",
       "      <td>FOREST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>images/forest/forest6.png</td>\n",
       "      <td>16.123850</td>\n",
       "      <td>-0.502807</td>\n",
       "      <td>-31.532553</td>\n",
       "      <td>-26.753161</td>\n",
       "      <td>22.110188</td>\n",
       "      <td>-44.973076</td>\n",
       "      <td>35.949924</td>\n",
       "      <td>-20.104215</td>\n",
       "      <td>-12.638088</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.407842</td>\n",
       "      <td>32.373979</td>\n",
       "      <td>-28.167140</td>\n",
       "      <td>-7.078691</td>\n",
       "      <td>5.199906</td>\n",
       "      <td>-50.789380</td>\n",
       "      <td>5.619568</td>\n",
       "      <td>-30.189872</td>\n",
       "      <td>OUTDOORS</td>\n",
       "      <td>FOREST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>images/forest/forest7.png</td>\n",
       "      <td>15.871565</td>\n",
       "      <td>-0.763786</td>\n",
       "      <td>-24.201742</td>\n",
       "      <td>-24.479100</td>\n",
       "      <td>12.975591</td>\n",
       "      <td>-41.588451</td>\n",
       "      <td>26.818111</td>\n",
       "      <td>-6.913483</td>\n",
       "      <td>-4.095325</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.867910</td>\n",
       "      <td>33.380044</td>\n",
       "      <td>-22.327289</td>\n",
       "      <td>-11.202320</td>\n",
       "      <td>-10.254014</td>\n",
       "      <td>-26.236774</td>\n",
       "      <td>4.476926</td>\n",
       "      <td>-4.142449</td>\n",
       "      <td>OUTDOORS</td>\n",
       "      <td>FOREST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>images/forest/forest8.png</td>\n",
       "      <td>17.764418</td>\n",
       "      <td>-4.284194</td>\n",
       "      <td>-27.631842</td>\n",
       "      <td>-49.291224</td>\n",
       "      <td>12.780080</td>\n",
       "      <td>-43.668120</td>\n",
       "      <td>34.199202</td>\n",
       "      <td>-25.522677</td>\n",
       "      <td>10.561731</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.800392</td>\n",
       "      <td>7.948283</td>\n",
       "      <td>-31.925772</td>\n",
       "      <td>8.836070</td>\n",
       "      <td>-18.177841</td>\n",
       "      <td>-10.745605</td>\n",
       "      <td>-16.128549</td>\n",
       "      <td>5.578362</td>\n",
       "      <td>OUTDOORS</td>\n",
       "      <td>FOREST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>images/forest/forest9.png</td>\n",
       "      <td>17.008391</td>\n",
       "      <td>-7.689599</td>\n",
       "      <td>-23.670928</td>\n",
       "      <td>-35.503255</td>\n",
       "      <td>16.394963</td>\n",
       "      <td>-54.073955</td>\n",
       "      <td>22.142703</td>\n",
       "      <td>-24.226244</td>\n",
       "      <td>0.829439</td>\n",
       "      <td>...</td>\n",
       "      <td>-40.544998</td>\n",
       "      <td>13.595717</td>\n",
       "      <td>-19.715312</td>\n",
       "      <td>-8.342403</td>\n",
       "      <td>-14.912854</td>\n",
       "      <td>-24.710224</td>\n",
       "      <td>9.749967</td>\n",
       "      <td>-10.477606</td>\n",
       "      <td>OUTDOORS</td>\n",
       "      <td>FOREST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       IMAGE     mfcc_1     mfcc_2     mfcc_3     mfcc_4  \\\n",
       "0  images/forest/forest0.png  15.795384  -3.442518 -25.316836 -33.412104   \n",
       "1  images/forest/forest1.png  15.883880  -3.494075 -21.189490 -18.077115   \n",
       "2  images/forest/forest2.png  17.872629 -18.877467 -31.665319 -47.045579   \n",
       "3  images/forest/forest3.png  16.843997  -3.527753 -21.282970 -24.248141   \n",
       "4  images/forest/forest4.png  16.128583  -4.267328 -25.608325 -20.231084   \n",
       "5  images/forest/forest5.png  21.689841 -15.971450 -26.837817 -46.561006   \n",
       "6  images/forest/forest6.png  16.123850  -0.502807 -31.532553 -26.753161   \n",
       "7  images/forest/forest7.png  15.871565  -0.763786 -24.201742 -24.479100   \n",
       "8  images/forest/forest8.png  17.764418  -4.284194 -27.631842 -49.291224   \n",
       "9  images/forest/forest9.png  17.008391  -7.689599 -23.670928 -35.503255   \n",
       "\n",
       "      mfcc_5     mfcc_6     mfcc_7     mfcc_8     mfcc_9   ...      mfcc_97  \\\n",
       "0   2.447290 -46.981182  12.889984 -23.588534 -22.625879   ...   -43.876462   \n",
       "1   4.284962 -27.014271   3.666955  -9.091312  -3.746509   ...   -33.883092   \n",
       "2   1.813430 -45.899877  14.975982 -24.462396  -1.812962   ...   -34.456028   \n",
       "3  27.201589 -18.787674  30.093938  -1.922008  10.156418   ...   -36.410615   \n",
       "4  15.922823 -35.703313  16.307644  -3.547505   4.804142   ...   -41.548915   \n",
       "5  20.770073  -8.153000  16.801556  -4.589764   7.219863   ...   -21.613514   \n",
       "6  22.110188 -44.973076  35.949924 -20.104215 -12.638088   ...   -53.407842   \n",
       "7  12.975591 -41.588451  26.818111  -6.913483  -4.095325   ...   -37.867910   \n",
       "8  12.780080 -43.668120  34.199202 -25.522677  10.561731   ...   -39.800392   \n",
       "9  16.394963 -54.073955  22.142703 -24.226244   0.829439   ...   -40.544998   \n",
       "\n",
       "     mfcc_98    mfcc_99   mfcc_100   mfcc_101   mfcc_102   mfcc_103  \\\n",
       "0  20.697491 -22.793173  -9.417196  13.762870 -31.976786  18.461561   \n",
       "1  17.223236 -24.985005  12.035913   8.321000 -16.249293   8.717523   \n",
       "2  21.433239 -14.190274  -8.629235   1.035640 -20.703358   5.986662   \n",
       "3  19.949251  -5.466172   6.480569  13.070739 -14.853299  10.243606   \n",
       "4  15.697646 -20.615005 -11.942869   5.421639 -27.445147   9.060233   \n",
       "5  42.223289 -11.695203   2.910106 -35.891702  -2.755247  -2.448610   \n",
       "6  32.373979 -28.167140  -7.078691   5.199906 -50.789380   5.619568   \n",
       "7  33.380044 -22.327289 -11.202320 -10.254014 -26.236774   4.476926   \n",
       "8   7.948283 -31.925772   8.836070 -18.177841 -10.745605 -16.128549   \n",
       "9  13.595717 -19.715312  -8.342403 -14.912854 -24.710224   9.749967   \n",
       "\n",
       "    mfcc_104    CLASS1  CLASS2  \n",
       "0 -13.140673  OUTDOORS  FOREST  \n",
       "1   0.743640  OUTDOORS  FOREST  \n",
       "2 -14.644013  OUTDOORS  FOREST  \n",
       "3 -17.983957  OUTDOORS  FOREST  \n",
       "4 -15.077528  OUTDOORS  FOREST  \n",
       "5  13.279929  OUTDOORS  FOREST  \n",
       "6 -30.189872  OUTDOORS  FOREST  \n",
       "7  -4.142449  OUTDOORS  FOREST  \n",
       "8   5.578362  OUTDOORS  FOREST  \n",
       "9 -10.477606  OUTDOORS  FOREST  \n",
       "\n",
       "[10 rows x 107 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/dataset.csv', delimiter=',', nrows=None)\n",
    "data_train = np.array(data)\n",
    "\n",
    "audio = data_train[:,1:-2].astype('float32') #last index of the interval isn't included in the range : CLASS1\n",
    "labels = data_train[:,-1]\n",
    "img_paths = data['IMAGE']\n",
    "\n",
    "img_train, img_temp, audio_train, audio_temp, labels_train, labels_temp = train_test_split(img_paths, audio, labels, train_size=0.6)\n",
    "img_val, img_test, audio_val, audio_test, labels_val, labels_test = train_test_split(img_temp, audio_temp, labels_temp, train_size=0.5)\n",
    "\n",
    "print(np.shape(audio_train))\n",
    "print(np.shape(audio_val))\n",
    "print(np.shape(audio_test))\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit les seeds qui permettent de générer aléatoirement les mêmes nombres, et donc rendre les résultats reproductibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch Dataset**\n",
    "\n",
    "On créé une classe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_type, root_dir, img_data, audio_data, labels=None, img_transform=None, audio_transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_data = img_data\n",
    "        self.audio_data = audio_data\n",
    "        self.labels = labels\n",
    "        self.img_transform = img_transform\n",
    "        self.audio_transform = audio_transform\n",
    "        self.data_type = data_type\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.data_type == \"img\":\n",
    "            img = os.path.join(self.root_dir, self.img_data.iloc[idx])\n",
    "            if self.img_transform:\n",
    "                img = self.img_transform(img)\n",
    "            audio = None\n",
    "            \n",
    "        elif self.data_type == \"audio\":\n",
    "            audio = self.audio_data[idx,:]\n",
    "            if self.audio_transform:\n",
    "                audio = self.audio_transform(audio)\n",
    "            img = None\n",
    "        \n",
    "        elif self.data_type == \"imgaudio\":\n",
    "            img = os.path.join(self.root_dir, self.img_paths.iloc[idx])\n",
    "            audio = self.audio_data[idx,:]\n",
    "            if self.img_transform:\n",
    "                img = self.img_transform(img)\n",
    "                audio = self.audio_transform(audio)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Data must be img, audio or imgaudio')\n",
    "                               \n",
    "        return ( data_type, img, audio if labels is None else  data_type, img, audio, self.labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BASELINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain\\npredict\\n\\ndata augmentation\\nload data imag\\nget imagenet pretrained model --> compare feature extraction and transfer learning 2 last layers\\nuse train\\nuse predict\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from random import seed\n",
    "from random import randrange\n",
    "\n",
    "def zero_rule_algorithm_classification(train, test):\n",
    "    output_values = [row[-1] for row in train]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    predicted = [prediction for i in range(len(test))]\n",
    "    return predicted\n",
    "\n",
    "seed(1)\n",
    "\n",
    "predictions = zero_rule_algorithm_classification(data_train, data_train)\n",
    "#print(predictions)\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "train\n",
    "predict\n",
    "\n",
    "data augmentation\n",
    "load data imag\n",
    "get imagenet pretrained model --> compare feature extraction and transfer learning 2 last layers\n",
    "use train\n",
    "use predict\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, criterion, optimizer, scheduler, epochs=20):\n",
    "    \n",
    "    print(\"trainloader :\", train_loader[0], \"\\nval_loader :\",  val_loader[0])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for index, data in enumerate(train_loader):\n",
    "            data_type, img, audio, labels = data\n",
    "            img, audio, labels = img.cuda(), audio.cuda(), labels.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "          \n",
    "        #We compute validation data accuracy on each epoch to prevent overfitting \n",
    "        #if val_accuracy isn't improved by current training epoch\n",
    "        val_acc = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad: #Validation data aim to test, not to train NN --> grad isn't needed\n",
    "            for dat_type, img, audio, imgaudio, labl in val_loader:\n",
    "                img, audio, labels = img.cuda(), audio.cuda(), labels.cuda()\n",
    "                if data_type == \"img\":\n",
    "                    outputs = model(img)\n",
    "                elif data_type == \"audio\":\n",
    "                    outputs = model(audio)\n",
    "                else:\n",
    "                    outputs = model(img, audio)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREDICT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size=\"6\" color=\"darkblue\">IMAGES</font>**\n",
    "\n",
    "Explication données image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMAGE VISUALIZATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA TRANSFORMATION** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# DA : Data Augmentation\n",
    "# DP : Data Preparation --> transform data to a more ergonomic data format\n",
    "\n",
    "img_train_transform = transforms.Compose([ #Compose is used to chain multiple transforms to create a transformation pipeline\n",
    "    transforms.RandomResizedCrop(224), #DA\n",
    "    transforms.RandomHorizontalFlip(), #DA\n",
    "    transforms.ToTensor(), #DP to compute on GPU\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) #DP\n",
    "])\n",
    "img_val_transform = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop(224),\n",
    "    transforms.Resize(256), #DA fixed resize and crop for reliability\n",
    "    transforms.CenterCrop(224),# DA\n",
    "    transforms.ToTensor(), #DP\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) #DP\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMAGE LOADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "data_type = 'img'\n",
    "train_data = CustomDataset(data_type=data_type, root_dir='/data', img_data=img_train, audio_data=audio_train, labels=labels_train, img_transform=img_train_transform)\n",
    "val_data = CustomDataset(data_type=data_type, root_dir='/data', img_data=img_val,  audio_data=audio_val,labels=labels_val, img_transform=img_val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFER LEARNING** \n",
    "\n",
    "on charge le réseau préentrainé\n",
    "On utilise Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-342c2532f8a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mresnext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mresnext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\université paris sud\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \"\"\"\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\université paris sud\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\université paris sud\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\université paris sud\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \"\"\"\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\université paris sud\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;31m# are found or any other error occurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[1;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;31m# we need to just return without initializing in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import torchvision.models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "resnext = torchvision.models.resnext50_32x4d(pretrained=True, progress=True)\n",
    "\n",
    "for param in resnext.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_ftrs = resnext.fc.in_features\n",
    "resnext.fc = nn.Linear(num_ftrs, 9)\n",
    "\n",
    "resnext = resnext.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(resnext.fc.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=0,factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResNet' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-389e0ab5d2bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresnext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresnext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-8f6347f7d888>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, val_loader, model, criterion, optimizer, scheduler, epochs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trainloader :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\nval_loader :\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mval_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ResNet' object does not support indexing"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = 30\n",
    "resnext, loss_vals, train_acc_vals, val_acc_vals = train(resnext, train_loader, val_loader, criterion, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size=\"6\" color=\"darkblue\">AUDIO</font>**\n",
    "\n",
    "Type de données MCCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUDIO DATA VISUALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(audio[::,0])\n",
    "plt.title('mfcc_1')\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(audio[::,1])\n",
    "plt.title('mfcc_2')\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(audio[::,2])\n",
    "plt.title('mfcc_3')\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(audio[::,3])\n",
    "plt.title('mfcc_4')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-80ed2f8119a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mmlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\université paris sud\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \"\"\"\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\université paris sud\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\université paris sud\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\université paris sud\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \"\"\"\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\université paris sud\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;31m# are found or any other error occurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[1;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;31m# we need to just return without initializing in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(104, 156)\n",
    "        self.bn1 = nn.BatchNorm1d(156)\n",
    "        \n",
    "        self.linear2 = nn.Linear(156, 208)\n",
    "        self.bn2 = nn.BatchNorm1d(208)\n",
    "        \n",
    "        self.linear3 = nn.Linear(208, 156)\n",
    "        self.bn3 = nn.BatchNorm1d(156)\n",
    "        \n",
    "        self.linear4 = nn.Linear(156, 104)\n",
    "        self.bn4 = nn.BatchNorm1d(104)\n",
    "        \n",
    "        self.linear5 = nn.Linear(104, 64)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "\n",
    "\n",
    "        self.final = nn.Linear(64,9)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.linear2(x)))\n",
    "        x = F.leaky_relu(self.bn3(self.linear3(x)))\n",
    "        x = F.leaky_relu(self.bn4(self.linear4(x)))\n",
    "        x = F.leaky_relu(self.bn5(self.linear5(x)))\n",
    "\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "\n",
    "mlp = MLP().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA PROCESSING METHODS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return (data - np.mean(data, axis=0))/np.std(data, axis=0)\n",
    "\n",
    "audio_train = normalize(audio_train)\n",
    "audio_val = normalize(audio_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise:\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCircularShift:      \n",
    "    def __call__(self, tensor):\n",
    "        return torch.roll(tensor, 13*np.random.randint(8),dims=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUDIO DATA TRANSFORMATION** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-5cc8d1f7d9fc>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-38-5cc8d1f7d9fc>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    RandomCircularShift()\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "audio_train_transform = transforms.Compose([\n",
    "    AddGaussianNoise(0.0, 0.1)\n",
    "    RandomCircularShift()\n",
    "])\n",
    "\n",
    "audio_val_transform = transforms.Compose([\n",
    "    AddGaussianNoise(0.0, 0.1)\n",
    "    RandomCircularShift()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUDIO DATA LOADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'audio'\n",
    "train_data = CustomDataset(data_type=data_type, root_dir='/data', img_data=img_train, audio_data=audio_train, labels=labels_train, audio_transform=audio_train_transform)\n",
    "val_data = CustomDataset(data_type=data_type, root_dir='/data', img_data=img_val, audio_data=audio_val, labels=labels_val, audio_transform=audio_val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnext.fc.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=0,factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResNet' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-f5d89a70ffbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresnext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresnext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-8f6347f7d888>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, val_loader, model, criterion, optimizer, scheduler, epochs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trainloader :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\nval_loader :\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mval_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ResNet' object does not support indexing"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "resnext, loss_vals, train_acc_vals, val_acc_vals = train(resnext, train_loader, val_loader, criterion, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
