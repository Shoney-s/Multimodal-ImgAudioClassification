{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport random\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:45:47.325307Z","iopub.execute_input":"2021-05-22T11:45:47.325680Z","iopub.status.idle":"2021-05-22T11:45:48.168640Z","shell.execute_reply.started":"2021-05-22T11:45:47.325650Z","shell.execute_reply":"2021-05-22T11:45:48.167804Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Context**\n\nKaggle dataset lien https://www.kaggle.com/birdy654/scene-classification-images-and-audio","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/scene-classification-images-and-audio/dataset.csv', delimiter=',', nrows=None)\ndata_train = np.array(data)\n\naudio = data_train[:,1:-2].astype('float32') #last index of the interval isn't included in the range : CLASS1\nlabels = data_train[:,-1]\nimg_paths = data['IMAGE']\n\nimg_train, img_temp, audio_train, audio_temp, labels_train, labels_temp = train_test_split(img_paths, audio, labels, train_size=0.6)\nimg_val, img_test, audio_val, audio_test, labels_val, labels_test = train_test_split(img_temp, audio_temp, labels_temp, train_size=0.5)\n\nprint(np.shape(audio_train))\nprint(np.shape(audio_val))\nprint(np.shape(audio_test))\ndata.head(10)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:45:48.171744Z","iopub.execute_input":"2021-05-22T11:45:48.172010Z","iopub.status.idle":"2021-05-22T11:45:49.052002Z","shell.execute_reply.started":"2021-05-22T11:45:48.171985Z","shell.execute_reply":"2021-05-22T11:45:49.051132Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(10351, 104)\n(3450, 104)\n(3451, 104)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                       IMAGE     mfcc_1     mfcc_2     mfcc_3     mfcc_4  \\\n0  images/forest/forest0.png  15.795384  -3.442518 -25.316836 -33.412104   \n1  images/forest/forest1.png  15.883880  -3.494075 -21.189490 -18.077115   \n2  images/forest/forest2.png  17.872629 -18.877467 -31.665319 -47.045579   \n3  images/forest/forest3.png  16.843997  -3.527753 -21.282970 -24.248141   \n4  images/forest/forest4.png  16.128583  -4.267328 -25.608325 -20.231084   \n5  images/forest/forest5.png  21.689841 -15.971450 -26.837817 -46.561006   \n6  images/forest/forest6.png  16.123850  -0.502807 -31.532553 -26.753161   \n7  images/forest/forest7.png  15.871565  -0.763786 -24.201742 -24.479100   \n8  images/forest/forest8.png  17.764418  -4.284194 -27.631842 -49.291224   \n9  images/forest/forest9.png  17.008391  -7.689599 -23.670928 -35.503255   \n\n      mfcc_5     mfcc_6     mfcc_7     mfcc_8     mfcc_9  ...    mfcc_97  \\\n0   2.447290 -46.981182  12.889984 -23.588534 -22.625879  ... -43.876462   \n1   4.284962 -27.014271   3.666955  -9.091312  -3.746509  ... -33.883092   \n2   1.813430 -45.899877  14.975982 -24.462396  -1.812962  ... -34.456028   \n3  27.201589 -18.787674  30.093938  -1.922008  10.156418  ... -36.410615   \n4  15.922823 -35.703313  16.307644  -3.547505   4.804142  ... -41.548915   \n5  20.770073  -8.153000  16.801556  -4.589764   7.219863  ... -21.613514   \n6  22.110188 -44.973076  35.949924 -20.104215 -12.638088  ... -53.407842   \n7  12.975591 -41.588451  26.818111  -6.913483  -4.095325  ... -37.867910   \n8  12.780080 -43.668120  34.199202 -25.522677  10.561731  ... -39.800392   \n9  16.394963 -54.073955  22.142703 -24.226244   0.829439  ... -40.544998   \n\n     mfcc_98    mfcc_99   mfcc_100   mfcc_101   mfcc_102   mfcc_103  \\\n0  20.697491 -22.793173  -9.417196  13.762870 -31.976786  18.461561   \n1  17.223236 -24.985005  12.035913   8.321000 -16.249293   8.717523   \n2  21.433239 -14.190274  -8.629235   1.035640 -20.703358   5.986662   \n3  19.949251  -5.466172   6.480569  13.070739 -14.853299  10.243606   \n4  15.697646 -20.615005 -11.942869   5.421639 -27.445147   9.060233   \n5  42.223289 -11.695203   2.910106 -35.891702  -2.755247  -2.448610   \n6  32.373979 -28.167140  -7.078691   5.199906 -50.789380   5.619568   \n7  33.380044 -22.327289 -11.202320 -10.254014 -26.236774   4.476926   \n8   7.948283 -31.925772   8.836070 -18.177841 -10.745605 -16.128549   \n9  13.595717 -19.715312  -8.342403 -14.912854 -24.710224   9.749967   \n\n    mfcc_104    CLASS1  CLASS2  \n0 -13.140673  OUTDOORS  FOREST  \n1   0.743640  OUTDOORS  FOREST  \n2 -14.644013  OUTDOORS  FOREST  \n3 -17.983957  OUTDOORS  FOREST  \n4 -15.077528  OUTDOORS  FOREST  \n5  13.279929  OUTDOORS  FOREST  \n6 -30.189872  OUTDOORS  FOREST  \n7  -4.142449  OUTDOORS  FOREST  \n8   5.578362  OUTDOORS  FOREST  \n9 -10.477606  OUTDOORS  FOREST  \n\n[10 rows x 107 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMAGE</th>\n      <th>mfcc_1</th>\n      <th>mfcc_2</th>\n      <th>mfcc_3</th>\n      <th>mfcc_4</th>\n      <th>mfcc_5</th>\n      <th>mfcc_6</th>\n      <th>mfcc_7</th>\n      <th>mfcc_8</th>\n      <th>mfcc_9</th>\n      <th>...</th>\n      <th>mfcc_97</th>\n      <th>mfcc_98</th>\n      <th>mfcc_99</th>\n      <th>mfcc_100</th>\n      <th>mfcc_101</th>\n      <th>mfcc_102</th>\n      <th>mfcc_103</th>\n      <th>mfcc_104</th>\n      <th>CLASS1</th>\n      <th>CLASS2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>images/forest/forest0.png</td>\n      <td>15.795384</td>\n      <td>-3.442518</td>\n      <td>-25.316836</td>\n      <td>-33.412104</td>\n      <td>2.447290</td>\n      <td>-46.981182</td>\n      <td>12.889984</td>\n      <td>-23.588534</td>\n      <td>-22.625879</td>\n      <td>...</td>\n      <td>-43.876462</td>\n      <td>20.697491</td>\n      <td>-22.793173</td>\n      <td>-9.417196</td>\n      <td>13.762870</td>\n      <td>-31.976786</td>\n      <td>18.461561</td>\n      <td>-13.140673</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>images/forest/forest1.png</td>\n      <td>15.883880</td>\n      <td>-3.494075</td>\n      <td>-21.189490</td>\n      <td>-18.077115</td>\n      <td>4.284962</td>\n      <td>-27.014271</td>\n      <td>3.666955</td>\n      <td>-9.091312</td>\n      <td>-3.746509</td>\n      <td>...</td>\n      <td>-33.883092</td>\n      <td>17.223236</td>\n      <td>-24.985005</td>\n      <td>12.035913</td>\n      <td>8.321000</td>\n      <td>-16.249293</td>\n      <td>8.717523</td>\n      <td>0.743640</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>images/forest/forest2.png</td>\n      <td>17.872629</td>\n      <td>-18.877467</td>\n      <td>-31.665319</td>\n      <td>-47.045579</td>\n      <td>1.813430</td>\n      <td>-45.899877</td>\n      <td>14.975982</td>\n      <td>-24.462396</td>\n      <td>-1.812962</td>\n      <td>...</td>\n      <td>-34.456028</td>\n      <td>21.433239</td>\n      <td>-14.190274</td>\n      <td>-8.629235</td>\n      <td>1.035640</td>\n      <td>-20.703358</td>\n      <td>5.986662</td>\n      <td>-14.644013</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>images/forest/forest3.png</td>\n      <td>16.843997</td>\n      <td>-3.527753</td>\n      <td>-21.282970</td>\n      <td>-24.248141</td>\n      <td>27.201589</td>\n      <td>-18.787674</td>\n      <td>30.093938</td>\n      <td>-1.922008</td>\n      <td>10.156418</td>\n      <td>...</td>\n      <td>-36.410615</td>\n      <td>19.949251</td>\n      <td>-5.466172</td>\n      <td>6.480569</td>\n      <td>13.070739</td>\n      <td>-14.853299</td>\n      <td>10.243606</td>\n      <td>-17.983957</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>images/forest/forest4.png</td>\n      <td>16.128583</td>\n      <td>-4.267328</td>\n      <td>-25.608325</td>\n      <td>-20.231084</td>\n      <td>15.922823</td>\n      <td>-35.703313</td>\n      <td>16.307644</td>\n      <td>-3.547505</td>\n      <td>4.804142</td>\n      <td>...</td>\n      <td>-41.548915</td>\n      <td>15.697646</td>\n      <td>-20.615005</td>\n      <td>-11.942869</td>\n      <td>5.421639</td>\n      <td>-27.445147</td>\n      <td>9.060233</td>\n      <td>-15.077528</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>images/forest/forest5.png</td>\n      <td>21.689841</td>\n      <td>-15.971450</td>\n      <td>-26.837817</td>\n      <td>-46.561006</td>\n      <td>20.770073</td>\n      <td>-8.153000</td>\n      <td>16.801556</td>\n      <td>-4.589764</td>\n      <td>7.219863</td>\n      <td>...</td>\n      <td>-21.613514</td>\n      <td>42.223289</td>\n      <td>-11.695203</td>\n      <td>2.910106</td>\n      <td>-35.891702</td>\n      <td>-2.755247</td>\n      <td>-2.448610</td>\n      <td>13.279929</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>images/forest/forest6.png</td>\n      <td>16.123850</td>\n      <td>-0.502807</td>\n      <td>-31.532553</td>\n      <td>-26.753161</td>\n      <td>22.110188</td>\n      <td>-44.973076</td>\n      <td>35.949924</td>\n      <td>-20.104215</td>\n      <td>-12.638088</td>\n      <td>...</td>\n      <td>-53.407842</td>\n      <td>32.373979</td>\n      <td>-28.167140</td>\n      <td>-7.078691</td>\n      <td>5.199906</td>\n      <td>-50.789380</td>\n      <td>5.619568</td>\n      <td>-30.189872</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>images/forest/forest7.png</td>\n      <td>15.871565</td>\n      <td>-0.763786</td>\n      <td>-24.201742</td>\n      <td>-24.479100</td>\n      <td>12.975591</td>\n      <td>-41.588451</td>\n      <td>26.818111</td>\n      <td>-6.913483</td>\n      <td>-4.095325</td>\n      <td>...</td>\n      <td>-37.867910</td>\n      <td>33.380044</td>\n      <td>-22.327289</td>\n      <td>-11.202320</td>\n      <td>-10.254014</td>\n      <td>-26.236774</td>\n      <td>4.476926</td>\n      <td>-4.142449</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>images/forest/forest8.png</td>\n      <td>17.764418</td>\n      <td>-4.284194</td>\n      <td>-27.631842</td>\n      <td>-49.291224</td>\n      <td>12.780080</td>\n      <td>-43.668120</td>\n      <td>34.199202</td>\n      <td>-25.522677</td>\n      <td>10.561731</td>\n      <td>...</td>\n      <td>-39.800392</td>\n      <td>7.948283</td>\n      <td>-31.925772</td>\n      <td>8.836070</td>\n      <td>-18.177841</td>\n      <td>-10.745605</td>\n      <td>-16.128549</td>\n      <td>5.578362</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>images/forest/forest9.png</td>\n      <td>17.008391</td>\n      <td>-7.689599</td>\n      <td>-23.670928</td>\n      <td>-35.503255</td>\n      <td>16.394963</td>\n      <td>-54.073955</td>\n      <td>22.142703</td>\n      <td>-24.226244</td>\n      <td>0.829439</td>\n      <td>...</td>\n      <td>-40.544998</td>\n      <td>13.595717</td>\n      <td>-19.715312</td>\n      <td>-8.342403</td>\n      <td>-14.912854</td>\n      <td>-24.710224</td>\n      <td>9.749967</td>\n      <td>-10.477606</td>\n      <td>OUTDOORS</td>\n      <td>FOREST</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 107 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"On définit les seeds qui permettent de générer aléatoirement les mêmes nombres, et donc rendre les résultats reproductibles.","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(0)\ntorch.cuda.manual_seed_all(0)\nrandom.seed(0)\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:45:49.053698Z","iopub.execute_input":"2021-05-22T11:45:49.054064Z","iopub.status.idle":"2021-05-22T11:45:49.058246Z","shell.execute_reply.started":"2021-05-22T11:45:49.054025Z","shell.execute_reply":"2021-05-22T11:45:49.057359Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Pytorch Dataset**\n\nOn créé une classe Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass CustomDataset(Dataset):\n    def __init__(self, data_type, root_dir, img_data, audio_data, labels=None, img_transform=None, audio_transform=None):\n        self.root_dir = root_dir\n        self.img_data = img_data\n        self.audio_data = audio_data\n        self.labels = labels\n        self.img_transform = img_transform\n        self.audio_transform = audio_transform\n        self.data_type = data_type\n        \n    def __len__(self):\n        return len(self.img_data)\n        \n    def __getitem__(self, idx):\n        if self.data_type == \"img\":\n            img = os.path.join(self.root_dir, self.img_data.iloc[idx])\n            if self.img_transform:\n                img = self.img_transform(img)\n            audio = None\n            \n        elif self.data_type == \"audio\":\n            audio = self.audio_data[idx,:]\n            if self.audio_transform:\n                audio = self.audio_transform(audio)\n            img = None\n        \n        elif self.data_type == \"imgaudio\":\n            img = os.path.join(self.root_dir, self.img_paths.iloc[idx])\n            audio = self.audio_data[idx,:]\n            if self.img_transform:\n                img = self.img_transform(img)\n                audio = self.audio_transform(audio)\n\n        else:\n            raise ValueError('Data must be img, audio or imgaudio')\n                               \n        return ( data_type, img, audio if labels is None else  data_type, img, audio, self.labels[idx])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:45:49.060043Z","iopub.execute_input":"2021-05-22T11:45:49.060390Z","iopub.status.idle":"2021-05-22T11:45:49.072322Z","shell.execute_reply.started":"2021-05-22T11:45:49.060355Z","shell.execute_reply":"2021-05-22T11:45:49.071360Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**TRAIN**","metadata":{}},{"cell_type":"code","source":"def train(train_loader, val_loader, model, criterion, optimizer, scheduler, epochs=20):\n    \n    print(\"trainloader :\", train_loader[0], \"\\nval_loader :\",  val_loader[0])\n    \n    for epoch in range(epochs):\n        for index, data in enumerate(train_loader):\n            data_type, img, audio, labels = data\n            img, audio, labels = img.cuda(), audio.cuda(), labels.cuda()\n            \n            optimizer.zero_grad()\n          \n        #We compute validation data accuracy on each epoch to prevent overfitting \n        #if val_accuracy isn't improved by current training epoch\n        val_acc = 0\n        model.eval()\n        with torch.no_grad: #Validation data aim to test, not to train NN --> grad isn't needed\n            for data_type, img, audio, labels in val_loader:\n                img, audio, labels = img.cuda(), audio.cuda(), labels.cuda()\n                if data_type == \"img\":\n                    outputs = model(img)\n                elif data_type == \"audio\":\n                    outputs = model(audio)\n                else:\n                    outputs = model(img, audio)\n    return None","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:45:49.073774Z","iopub.execute_input":"2021-05-22T11:45:49.074146Z","iopub.status.idle":"2021-05-22T11:45:49.084382Z","shell.execute_reply.started":"2021-05-22T11:45:49.074110Z","shell.execute_reply":"2021-05-22T11:45:49.083625Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**PREDICT**","metadata":{}},{"cell_type":"code","source":"def predict(test_loader, model):\n    model.eval()\n    \n    with torch.no_grad: #Validation data aim to test, not to train NN --> grad isn't needed\n        for data_type, img, audio, labels in test_loader:\n            img, audio = img.cuda(), audio.cuda()\n        if data_type == \"img\":\n            outputs = model(img)\n        elif data_type == \"audio\":\n            outputs = model(audio)\n        else:\n             outputs = model(img, audio)\n                \n    return None","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:45:49.085859Z","iopub.execute_input":"2021-05-22T11:45:49.086325Z","iopub.status.idle":"2021-05-22T11:45:49.097081Z","shell.execute_reply.started":"2021-05-22T11:45:49.086289Z","shell.execute_reply":"2021-05-22T11:45:49.096221Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**<font size=\"6\" color=\"darkblue\">IMAGES</font>**\n\nExplication données image","metadata":{}},{"cell_type":"markdown","source":"**IMAGE VISUALIZATION**","metadata":{}},{"cell_type":"markdown","source":"**DATA TRANSFORMATION** ","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\n# DA : Data Augmentation\n# DP : Data Preparation --> transform data to a more ergonomic data format\n\nimg_train_transform = transforms.Compose([ #Compose is used to chain multiple transforms to create a transformation pipeline\n    transforms.RandomResizedCrop(224), #DA\n    transforms.RandomHorizontalFlip(), #DA\n    transforms.ToTensor(), #DP to compute on GPU\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) #DP\n])\nimg_val_transform = transforms.Compose([\n    #transforms.RandomResizedCrop(224),\n    transforms.Resize(256), #DA fixed resize and crop for reliability\n    transforms.CenterCrop(224),# DA\n    transforms.ToTensor(), #DP\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) #DP\n])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:45:49.098647Z","iopub.execute_input":"2021-05-22T11:45:49.099090Z","iopub.status.idle":"2021-05-22T11:45:49.107026Z","shell.execute_reply.started":"2021-05-22T11:45:49.099054Z","shell.execute_reply":"2021-05-22T11:45:49.106104Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**IMAGE LOADER**","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\ndata_type = 'img'\ntrain_data = CustomDataset(data_type=data_type, root_dir='/kaggle/input/scene-classification-images-and-audio', img_data=img_train, audio_data=audio_train, labels=labels_train, img_transform=img_train_transform)\nval_data = CustomDataset(data_type=data_type, root_dir='/kaggle/input/scene-classification-images-and-audio/', img_data=img_val,  audio_data=audio_val,labels=labels_val, img_transform=img_val_transform)\n\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:45:49.109980Z","iopub.execute_input":"2021-05-22T11:45:49.110270Z","iopub.status.idle":"2021-05-22T11:45:49.119640Z","shell.execute_reply.started":"2021-05-22T11:45:49.110243Z","shell.execute_reply":"2021-05-22T11:45:49.118735Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**TRANSFER LEARNING** \n\non charge le réseau préentrainé\nOn utilise Imagenet","metadata":{}},{"cell_type":"code","source":"import torchvision.models\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nresnext = torchvision.models.resnext50_32x4d(pretrained=True, progress=True)\n\nfor param in resnext.parameters():\n    param.requires_grad = False\n    \nnum_ftrs = resnext.fc.in_features\nresnext.fc = nn.Linear(num_ftrs, 9)\n\nresnext = resnext.cuda()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-05-22T11:45:49.121548Z","iopub.execute_input":"2021-05-22T11:45:49.122012Z","iopub.status.idle":"2021-05-22T11:45:49.681494Z","shell.execute_reply.started":"2021-05-22T11:45:49.121975Z","shell.execute_reply":"2021-05-22T11:45:49.680601Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.optim import lr_scheduler\nimport torch.optim as optim\n\noptimizer = optim.Adam(resnext.fc.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=0,factor=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:45:49.683364Z","iopub.execute_input":"2021-05-22T11:45:49.683920Z","iopub.status.idle":"2021-05-22T11:45:49.689470Z","shell.execute_reply.started":"2021-05-22T11:45:49.683871Z","shell.execute_reply":"2021-05-22T11:45:49.688766Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nepochs = 30\nresnext, loss_vals, train_acc_vals, val_acc_vals = train(resnext, train_loader, val_loader, criterion, optimizer, scheduler, epochs)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:45:49.690764Z","iopub.execute_input":"2021-05-22T11:45:49.691147Z","iopub.status.idle":"2021-05-22T11:45:49.746606Z","shell.execute_reply.started":"2021-05-22T11:45:49.691109Z","shell.execute_reply":"2021-05-22T11:45:49.745477Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-389e0ab5d2bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-f40ec88a1eef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, model, criterion, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainloader :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nval_loader :\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mval_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'ResNet' object is not subscriptable"],"ename":"TypeError","evalue":"'ResNet' object is not subscriptable","output_type":"error"}]},{"cell_type":"markdown","source":"**<font size=\"6\" color=\"darkblue\">AUDIO</font>**\n\nType de données MCCF","metadata":{}},{"cell_type":"markdown","source":"**AUDIO DATA VISUALIZATION**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.subplot(2,2,1)\nplt.hist(audio[::,0])\nplt.title('mfcc_1')\nplt.subplot(2,2,2)\nplt.hist(audio[::,1])\nplt.title('mfcc_2')\nplt.subplot(2,2,3)\nplt.hist(audio[::,2])\nplt.title('mfcc_3')\nplt.subplot(2,2,4)\nplt.hist(audio[::,3])\nplt.title('mfcc_4')\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:46:01.766129Z","iopub.execute_input":"2021-05-22T11:46:01.766448Z","iopub.status.idle":"2021-05-22T11:46:02.252477Z","shell.execute_reply.started":"2021-05-22T11:46:01.766418Z","shell.execute_reply":"2021-05-22T11:46:02.251716Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 4 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAe5UlEQVR4nO3df7BV5X3v8fen4I+MxIiBcI2Chyg2F3snqIzasc31lgQQE9FJY7Gp0tQEvYWOTmpSTDqjo3EGbaKtNTFDAreYaikxGhl/RNFob52pykGNCkg8KghcBCLG3yFBv/eP9RyzxX0OnLP3XuvZ+3xeM3v2Ws/6sb/r7P3ly3r22s9SRGBmZpab36s6ADMzs3pcoMzMLEsuUGZmliUXKDMzy5ILlJmZZckFyszMsuQCZWZmWXKB6kCSzpC0UdLrko6pOh6z3Dln8uQC1Zm+BcyLiBER8VgzdyxpnqRuSTsl/Usz921WoZbkjKT9JC2StEHSa5Iel3RKs/bf6YZXHYC1xOHA6hbt+/8B3wSmAR9o0WuYla1VOTMc2Aj8T+AFYAawTNL/iIj1LXi9juIzqDYhab2kr0p6QtIb6X9lYyTdlf5ndm+afx0YBvxc0rNp27GSbpG0XdJLkq6r2e+XJa1N+1gj6dj+4oiIWyLiJ8BLrTxes0blkDMR8UZEXBoR6yPinYi4HXgeOK7Vx98JfAbVXj4HfJrifXsMOAY4F1gL3AmcHxEjJAXwiYjokTQMuB34GXA28DYwGUDS54FLgdOBbuAI4LclHo9Zq2WVM5LGAEfRuh6OjuIC1V7+OSK2Akj6T2Bbb3+5pFuBKXW2OR74KPDViNiV2h5Mz18CroqIlWm+p2WRm1Ujm5yRtA9wI7AkIp4e8JEMQe7iay9ba6bfqjM/os42Y4ENNYm2+7JnmxeeWXayyBlJvwf8EPgNMG+g2w9VLlCdbyMwTlK9s+WNFF0UZvY7Tc0ZSQIWAWOAz0WEu9H3kgtU53sE2AIskHSApP0lnZSW/QC4SNJxKhwp6fD+diZpuKT9Kb5UHpb2565i6yRNzRngeuC/A5+NiLdaGHfHcYHqcBHxNvBZ4EiKy1w3AX+Wlv0IuAK4CXgN+Alw8B52+fcUXSPzgb9I03/fgtDNKtHMnEnF6zxgEvBi+iHw65K+0MJD6BjyHXXNzCxHPoMyM7Ms+bsDew9J44A1fSyeGBEvlBmPWe6cM63jLj4zM8tS255BjRo1Krq6uqoOw4awVatW/TIiRlcdx95yzljVBpozbVugurq66O7urjoMG8Ikbag6hoFwzljVBpozvkjCzMyy5AJlZmZZcoEyM7Mste13UDb0dM2/Y1DbrV9wapMjsaFosJ8/8GdwsHwGZVYSSb+fbvnd+3hV0oWSLpW0uaZ9Rs02F0vqkbRO0rSa9umprUfS/GqOyKy1fAZlVpKIWEcxJhvppnibgVuBLwLXRMS3ateXNBGYBRxNcX+ieyUdlRZ/h+JGfJuAlZKWR0RfPxY1a0suUGbVmAI8GxEbirsx1DUTWBoRO4HnJfVQ3EwPoCcingOQtDSt6wJlHcVdfGbVmAX8W838PElPSFosaWRqO5Ti/kO9NqW2vtrfR9IcSd2Surdv39686M1KsMcClRJmm6SnatoOlrRC0jPpeWRql6RrU7/4E5KOrdlmdlr/GUmza9qPk/Rk2uZa9fPfSbNOIGlf4DTgR6npeoqb4E2iuA/Rt5v1WhGxMCImR8Tk0aPbZtALM2DvzqD+BZi+W9t84L6ImADcl+YBTgEmpMccisRD0sHAJcAJFF0Ul9T8L/F64Ms12+3+Wmad5hTg0YjYChARWyPi7Yh4B/g+v+vG20xxi/Feh6W2vtrNOsoeC1RE/F9gx27NM4ElaXoJcHpN+w1ReAg4SNIhwDRgRUTsiIiXgRXA9LTswIh4KIpRa2+o2ZdZpzqLmu69lAe9zgB6eyuWA7Mk7SdpPMV/4B4BVgITJI1PZ2Oz0rpmHWWwF0mMiYgtafpFYEyaHmif+aFpevd2s44k6QCKq+/Oq2m+StIkIID1vcsiYrWkZRQXP+wC5qa7vSJpHnA3MAxYHBGryzoGs7I0fBVfRISkUu7ZIWkORdch48aNK+MlzZoqIt4APrxb29n9rH8FxS3Gd2+/E7iz6QGaZWSwV/Ft7e2WSM/bUvtA+8w3p+nd2+vyF75mZkPHYAvUcqD3SrzZwG017eekq/lOBF5JXYF3A1MljUwXR0wF7k7LXpV0Yrp675yafZmZ2RC2xy4+Sf8GnAyMkrSJ4mq8BcAySecCG4Az0+p3AjOAHuBNil/IExE7JF1O8eUuwGUR0XvhxV9TXCn4AeCu9DAzsyFujwUqIs7qY9GUOusGMLeP/SwGFtdp7wb+YE9xmJnZ0OKRJMzMLEsuUGZmliUXKDMzy5ILlJmZZckFyszMsuQCZWZmWXKBMjOzLLlAmZlZllygzMwsSy5QZmaWJRcoMzPLkguUmZllyQXKzMyy5AJlZmZZcoEyM7MsuUCZlUjSeklPSnpcUndqO1jSCknPpOeRqV2SrpXUI+kJScfW7Gd2Wv8ZSbP7ej2zduYCZVa+/xURkyJicpqfD9wXEROA+9I8wCnAhPSYA1wPRUGjuLP1CcDxwCW9Rc2sk7hAmVVvJrAkTS8BTq9pvyEKDwEHSToEmAasiIgdEfEysAKYXnLMZi3nAmVWrgDukbRK0pzUNiYitqTpF4ExafpQYGPNtptSW1/tZh1leNUBmA0xfxQRmyV9BFgh6enahRERkqJZL5aK4ByAcePGNWu3ZqXwGZRZiSJic3reBtxK8R3S1tR1R3rellbfDIyt2fyw1NZXe73XWxgRkyNi8ujRo5t5KGYt5wJlVhJJB0j6YO80MBV4ClgO9F6JNxu4LU0vB85JV/OdCLySugLvBqZKGpkujpia2sw6irv4zMozBrhVEhS5d1NE/FTSSmCZpHOBDcCZaf07gRlAD/Am8EWAiNgh6XJgZVrvsojYUd5h2EB1zb9j0NuuX3BqEyNpLy5QZiWJiOeAT9RpfwmYUqc9gLl97GsxsLjZMZrlxF18ZmaWJRcoMzPLkguUmZllyQXKzMyy5AJlZmZZcoEyM7MsuUCZmVmWXKDMzCxLDRUo33zNzMxapRlnUL75mpmZNV0ruvh88zUzM2tYowWq1JuvSZojqVtS9/bt2xsM3czMctboYLGl3nwtIhYCCwEmT57ctP1aZ/NI0mbtqaEzqLJvvmZmZkPHoAuUb75mZmat1EgXn2++ZmZmLTPoAuWbr5mZWSt5JAkzM8uSC5SZmWXJBcrMzLLkAmVWEkljJd0vaY2k1ZIuSO2XStqcxrR8XNKMmm0uTuNXrpM0raZ9emrrkTS/3uuZtbtGf6hrZntvF/C3EfFo+onGKkkr0rJrIuJbtStLmgjMAo4GPgrcK+motPg7wKcpRl5ZKWl5RKwp5SjMSuICZVaS9Lu/LWn6NUlr6WNYr2QmsDQidgLPS+qh+DE8QE+6khZJS9O6LlB7oZGRRaxc7uIzq4CkLuAY4OHUNC/dhmZxzWj+Hr/ShjQXKLOSSRoB/Bi4MCJepbj1zBHAJIozrG8367UiYmFETI6IyaNHj27Wbs1K4S4+sxJJ2oeiON0YEbcARMTWmuXfB25Ps/2NU+nxK63j+QzKrCQqxgVbBKyNiKtr2g+pWe0MijEtoRi/cpak/SSNp7jZ5yMUw4JNkDRe0r4UF1IsL+MYzMrkMyiz8pwEnA08Kenx1PZ14CxJkyjur7YeOA8gIlZLWkZx8cMuYG5EvA0gaR7FoMrDgMURsbq8wzArhwuUWUki4kFAdRbd2c82VwBX1Gm/s7/tzDqBu/jMzCxLLlBmZpYlFygzM8uSC5SZmWXJBcrMzLLkAmVmZllygTIzsyy5QJmZWZZcoMzMLEsuUGZmliUXKDMzy5ILlJmZZckFyszMsuTRzM2s7XTNv6PqEErTyLGuX3BqEyMpnwuUlWoo/cNiZo1xF5+ZmWXJBcrMzLLkAmVmZllygTIzsyy5QJmZWZayKVCSpktaJ6lH0vyq4zHLnXPGOl0WBUrSMOA7wCnAROAsSROrjcosX84ZGwpy+R3U8UBPRDwHIGkpMBNYU2lUZvlq+5zxb+Jab7B/41x+4JtLgToU2Fgzvwk4YfeVJM0B5qTZ1yWtKyG2VhgF/LLqIBrUCccAezgOXdnvtoc3O5gBqDpncnr/c4oF8opnULHs4XM/WKMYYM7kUqD2SkQsBBZWHUejJHVHxOSq42hEJxwDdM5x9KVVOZPT3y2nWCCveDKMpWsg22TxHRSwGRhbM39YajOz+pwz1vFyKVArgQmSxkvaF5gFLK84JrOcOWes42XRxRcRuyTNA+4GhgGLI2J1xWG1Utt3U9IZxwBtehwZ5ExOf7ecYoG84mnrWBQRrQjEzMysIbl08ZmZmb2HC5SZmWXJBaokkv5B0tOSnpB0q6SDapZdnIarWSdpWoVh7pV2HGJH0lhJ90taI2m1pAtS+8GSVkh6Jj2PrDrWnEm6VNJmSY+nx4yaZaV+jvvKKUldkt6qifF7rY4lvW5ledHP57vP96uEmNZLejK9bndqG1i+RYQfJTyAqcDwNH0lcGWangj8HNgPGA88CwyrOt5+jmNYivFjwL4p9olVx7UXcR8CHJumPwj8Iv3trwLmp/b5ve+LH33+HS8FLqrTXvrnuJ+c6gKeKvnvUmle9PP5rvt+lRTTemDUbm0DyjefQZUkIu6JiF1p9iGK361AMTzN0ojYGRHPAz0Uw9jk6t0hdiLiN0DvEDtZi4gtEfFomn4NWEsxGsNMYElabQlweiUBtr/SP8f95FQVKs2Lfj7fuRlQvrlAVeOvgLvSdL0ha3L8YPVqt3jfR1IXcAzwMDAmIrakRS8CY6qKq43MS91qi2u6aKr+XNTmFMB4SY9J+g9Jf1zC61d9/O/a7fMN9d+vMgRwj6RVacgtGGC+ZfE7qE4h6V7gv9VZ9I2IuC2t8w1gF3BjmbFZQdII4MfAhRHxqqR3l0VESBryv7vo73MMXA9cTvGPz+XAtymKQ+mx9JNTW4BxEfGSpOOAn0g6OiJebVWcuajz+S71/drNH0XEZkkfAVZIerp24d7kmwtUE0XEp/pbLukvgc8AUyJ1wtJ+Q9a0W7zvkrQPRfLeGBG3pOatkg6JiC2SDgG2VRdhHvb0Oe4l6fvA7Wm2JZ+LweRUROwEdqbpVZKeBY4CuhuNpx+V50W9z3dEbK1ZXvt+tVxEbE7P2yTdStENOqB8cxdfSSRNB74GnBYRb9YsWg7MkrSfpPHABOCRKmLcS205xI6KU6VFwNqIuLpm0XJgdpqeDdxWdmztJP2j0usM4Kk0XfrnuK+ckjRaxf2ykPSxFMtzrYyFivOir893P+9Xq+M5QNIHe6cpLmh5igHmm8+gynMdxRVOK1K30kMRcX5ErJa0jOI+PruAuRHxdoVx9iuqH2JnsE4CzgaelPR4avs6sABYJulcYANwZjXhtY2rJE2i6DJaD5wHUNHnuG5OAZ8ELpP0W+Ad4PyI2NHKQDLIi74+32fVe79KMAa4Nb0vw4GbIuKnklYygHzzUEdmZpYld/GZmVmWXKDMzCxLLlBmZpYlFygzM8uSC5SZmWXJBcrMzLLkAmVmZllygTIzsyy5QJmZWZZcoMzMLEsuUGZmliUXKDMzy5ILlJmZZckFqgNJOkPSRkmvSzqm6njMcuecyZMLVGf6FjAvIkZExGPN3LGkf5W0RdKrkn4h6UvN3L9ZRVqWM70kTZD0a0n/2or9dyLfD6oDSdoFfDwielqw76OBnojYKenjwAPAqRGxqtmvZVaWVuZMzWvcA3wA2BARf9Gq1+kkPoNqE5LWS/qqpCckvSFpkaQxku6S9Jqke9P86xR39Py5pGfTtmMl3SJpu6SXJF1Xs98vS1qb9rFG0rH9xRERqyNiZ+9sehzRosM2G7RcciZtMwv4FXBfiw63I7lAtZfPAZ8GjgI+C9xFcVvn0RTv5fkRMSKt+4mIOELSMOB2itsrdwGHAksBJH0euBQ4BzgQOA14aU9BSPqupDeBp4EtwJ3NOTyzpqs8ZyQdCFwGfKWJxzUkDK86ABuQf46IrQCS/hPY1ttfLulWYEqdbY4HPgp8NSJ2pbYH0/OXgKsiYmWa36vujYj4a0l/A/whcDKws/8tzCqTQ85cDiyKiE2SBnkYQ5PPoNrL1prpt+rMj+D9xlL0ee/qY9mzgwkkIt6OiAeBw4D/PZh9mJWg0pyRNAn4FHDN3m5jv+MzqM63ERgnaXidhNtI498fDW/CPsxy0sycOZmim/CFdPY0AhgmaWJE7PG7q6HOZ1Cd7xGK74kWSDpA0v6STkrLfgBcJOk4FY6UdHhfO5L0EUmzJI2QNEzSNOAs/MWvdZam5QywkKKgTUqP7wF3ANNaFn0HcYHqcBHxNsWXw0cCLwCbgD9Ly34EXAHcBLwG/AQ4uL/dUXTnbQJepvjtyIURsbxF4ZuVrpk5ExFvRsSLvQ/gdeDXEbG9pQfRIfw7KDMzy5LPoMzMLEu+SMLeQ9I4YE0fiydGxAtlxmOWO+dM67iLz8zMstS2Z1CjRo2Krq6uqsOwIWzVqlW/jIjRVcext5wzVrWB5kzbFqiuri66u7urDsOGMEkbqo5hIJwzVrWB5owvkjAzsyy5QJmZWZZcoMzMLEtt+x2UFbrm3zHobdcvOLWJkZh1Nuda+XwGZWZmWXKBMjOzLLlAmZlZllygzMwsSy5QZmaWJRcoMzPLkguUmZllyQXKzMyy1FCBknSQpJslPS1praQ/lHSwpBWSnknPI9O6knStpB5JT0g6tmY/s9P6z0ia3ehBmZlZ+2v0DOqfgJ9GxMeBTwBrgfnAfRExAbgvzQOcAkxIjznA9QCSDgYuAU4Ajgcu6S1qZmY2dA26QEn6EPBJYBFARPwmIn4FzASWpNWWAKen6ZnADVF4CDhI0iHANGBFROyIiJeBFcD0wcZlljtJwyQ9Jun2ND9e0sOpd+HfJe2b2vdL8z1peVfNPi5O7eskTavoUMxaqpEzqPHAduD/pGT7gaQDgDERsSWt8yIwJk0fCmys2X5Tauur/X0kzZHULal7+/btDYRuVqkLKHobel0JXBMRRwIvA+em9nOBl1P7NWk9JE0EZgFHU/xn7ruShpUUu1lpGilQw4Fjgesj4hjgDX7XnQdAFPeTb9o95SNiYURMjojJo0e3zY1Mzd4l6TDgVOAHaV7AnwA3p1V273Xo7Y24GZiS1p8JLI2InRHxPNBD0T1u1lEaKVCbgE0R8XCav5miYG1NXXek521p+WZgbM32h6W2vtrNOtE/Al8D3knzHwZ+FRG70nxtD8K7vQtp+Stpffc62JAw6AIVES8CGyX9fmqaAqwBlgO9V+LNBm5L08uBc9LVfCcCr6SuwLuBqZJGposjpqY2s44i6TPAtohYVdZrutfB2lmj94P6G+DG9KXuc8AXKYreMknnAhuAM9O6dwIzKLoj3kzrEhE7JF0OrEzrXRYROxqMyyxHJwGnSZoB7A8cSHEl7EGShqezpNoehN7ehU2ShgMfAl7CvQ42RDRUoCLicWBynUVT6qwbwNw+9rMYWNxILGa5i4iLgYsBJJ0MXBQRX5D0I+BPgaW8v9dhNvBfafnPIiIkLQduknQ18FGKn248UuKhmJXCd9Q1q97fAUslfRN4jPTTjfT8Q0k9wA6KK/eIiNWSllF0qe8C5kbE2+WHbXvLd+MdHBcoswpExAPAA2n6OepchRcRvwY+38f2VwBXtC5Cs+p5LD4zM8uSz6DMbEhppLvNyuUzKDMzy5ILlJmZZckFyszMsuQCZWZmWXKBMjOzLLlAmZlZllygzMwsSy5QZmaWJRcoMzPLkguUmZllyQXKzMyy5AJlZmZZcoEyM7MsNVygJA2T9Jik29P8eEkPS+qR9O/pdvBI2i/N96TlXTX7uDi1r5M0rdGYzMys/TXjDOoCYG3N/JXANRFxJPAycG5qPxd4ObVfk9ZD0kSKO4UeDUwHvitpWBPiMjOzNtbQ/aAkHQacSnFnz69IEvAnwJ+nVZYAlwLXAzPTNMDNwHVp/ZnA0ojYCTyfbm99PPBfjcTWTnx/GjOz92v0DOofga8B76T5DwO/iohdaX4TcGiaPhTYCJCWv5LWf7e9zjbvIWmOpG5J3du3b28wdDMzy9mgC5SkzwDbImJVE+PpV0QsjIjJETF59OjRZb2smZlVoJEuvpOA0yTNAPYHDgT+CThI0vB0lnQYsDmtvxkYC2ySNBz4EPBSTXuv2m3MzGyIGvQZVERcHBGHRUQXxUUOP4uILwD3A3+aVpsN3Jaml6d50vKfRUSk9lnpKr/xwATgkcHGZWZmnaGhiyT68HfAUknfBB4DFqX2RcAP00UQOyiKGhGxWtIyYA2wC5gbEW+3IC4zM2sjTSlQEfEA8ECafo7iKrzd1/k18Pk+tr+C4kpAMzOr0chVvusXnNrESMrnkSTMzCxLLlBmZpYlFygzM8uSC5SZmWWpFVfxWZsY7Jev7f7Fq5m1B59BmZVE0lhJ90taI2m1pAtS+8GSVkh6Jj2PTO2SdG0a6f8JScfW7Gt2Wv8ZSbP7ek2zduYCZVaeXcDfRsRE4ERgbhrNfz5wX0RMAO5L8wCnUPxwfQIwh2LQZSQdDFwCnEDxk45LeouaWSdxgTIrSURsiYhH0/RrFLepOZRiRP8labUlwOlpeiZwQxQeohhG7BBgGrAiInZExMvACopb1Zh1FBcoswqkG3YeAzwMjImILWnRi8CYNN3XSP++A4ANCS5QZiWTNAL4MXBhRLxauyyNTxnNei3fAcDamQuUWYkk7UNRnG6MiFtS89bUdUd63pba+xrp33cAsCHBBcqsJOkO0ouAtRFxdc2i2pH+d78DwDnpar4TgVdSV+DdwFRJI9PFEVNTm1lH8e+gzMpzEnA28KSkx1Pb14EFwDJJ5wIbgDPTsjuBGUAP8CbwRYCI2CHpcmBlWu+yiNhRyhGYlcgFyqwkEfEgoD4WT6mzfgBz+9jXYmBx86Izy4+7+MzMLEs+gzKzttPIPZKsffgMyszMsjToAuVxxczMrJUaOYPyuGJmZtYygy5QHlfMzMxaqSnfQXlcMTMza7aGC5THFTMzs1Zo6DLz/sYVi4gtAxhX7OTd2h9oJK4q+LJXM7PmauQqPo8rZmZmLdPIGZTHFTMzs5YZdIHyuGJmZtZKHknCzMyy5AJlZmZZcoEyM7MsuUCZmVmWXKDMzCxLLlBmZpYlFygzM8uSC5SZmWXJBcrMzLLkAmVmZllygTIzsyw1dLsNM7PB8i1qbE9coMzMOtRg/xOwfsGpTY5kcFygbMAa+Z9vLh98M8ufv4MyM7Ms+QxqN+4XNzPLg8+gzMwsS9kUKEnTJa2T1CNpftXxmOXOOWOdLosuPknDgO8AnwY2ASslLY+INdVGZs3mCyyaI6eccbe4tUoWBQo4HuiJiOcAJC0FZgKDSjYnTGdq90tmm8w5Yy2Ty38kcylQhwIba+Y3ASfsvpKkOcCcNPu6pHV19jUK+GXTI2wexzd4g4pNV7YgksLhLdvznjUzZ8qW62cs17gg39jeF9ce8m1AOZNLgdorEbEQWNjfOpK6I2JySSENmOMbvJxjy9Xe5EzZcn0fc40L8o2t1XHlcpHEZmBszfxhqc3M6nPOWMfLpUCtBCZIGi9pX2AWsLzimMxy5pyxjpdFF19E7JI0D7gbGAYsjojVg9xdVt0ZdTi+wcs5tlI1OWfKluv7mGtckG9sLY1LEdHK/ZuZmQ1KLl18ZmZm7+ECZWZmWeqYAiXpUkmbJT2eHjNqll2choNZJ2laRfH9g6SnJT0h6VZJB6X2Lklv1cT9vYriy2bYHEljJd0vaY2k1ZIuSO19vseWt5zzM+fczCUvK8vJiOiIB3ApcFGd9onAz4H9gPHAs8CwCuKbCgxP01cCV6bpLuCpiv92w9Lf5WPAvunvNbHCeA4Bjk3THwR+kd7Huu+xH/k/cs7PXHMzp7ysKic75gyqHzOBpRGxMyKeB3oohokpVUTcExG70uxDFL9bycW7w+ZExG+A3mFzKhERWyLi0TT9GrCWYuQE6zyV52fGuZlNXlaVk51WoOal0/TFkkamtnpDwlT9j91fAXfVzI+X9Jik/5D0xxXEk+PfCCi6WYBjgIdTU7332NpDO+RnTrmZ298GKDcn26pASbpX0lN1HjOB64EjgEnAFuDbmcXXu843gF3AjalpCzAuIo4BvgLcJOnAsmPPkaQRwI+BCyPiVTJ4j61vOeenc7M5ys7JLH6ou7ci4lN7s56k7wO3p9nShoTZU3yS/hL4DDAlUmduROwEdqbpVZKeBY4CulsRYx+yGzZH0j4UiXBjRNwCEBFba5bXvseWgZzzs01zM6u8rCIn2+oMqj+SDqmZPQN4Kk0vB2ZJ2k/SeGAC8EgF8U0HvgacFhFv1rSPVnFvHyR9LMX3XMnhZTVsjiQBi4C1EXF1TXtf77FlLuf8zDg3s8nLqnKyrc6g9uAqSZOAANYD5wFExGpJyyjuk7MLmBsRb1cQ33UUVyqtKN5rHoqI84FPApdJ+i3wDnB+ROwoM7DIb9ick4CzgSclPZ7avg6cVe89traQc35mmZuZ5WUlOemhjszMLEsd08VnZmadxQXKzMyy5AJlZmZZcoEyM7MsuUCZmVmWXKDMzCxLLlBmZpal/w+MlFXoxBfC7wAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self):\n        super(MLP, self).__init__()\n        \n        self.linear1 = nn.Linear(104, 156)\n        self.bn1 = nn.BatchNorm1d(156)\n        \n        self.linear2 = nn.Linear(156, 208)\n        self.bn2 = nn.BatchNorm1d(208)\n        \n        self.linear3 = nn.Linear(208, 156)\n        self.bn3 = nn.BatchNorm1d(156)\n        \n        self.linear4 = nn.Linear(156, 104)\n        self.bn4 = nn.BatchNorm1d(104)\n        \n        self.linear5 = nn.Linear(104, 64)\n        self.bn5 = nn.BatchNorm1d(64)\n\n\n        self.final = nn.Linear(64,9)\n      \n    def forward(self, x):\n        x = F.leaky_relu(self.bn1(self.linear1(x)))\n        x = F.leaky_relu(self.bn2(self.linear2(x)))\n        x = F.leaky_relu(self.bn3(self.linear3(x)))\n        x = F.leaky_relu(self.bn4(self.linear4(x)))\n        x = F.leaky_relu(self.bn5(self.linear5(x)))\n\n        x = self.final(x)\n        return x\n\nmlp = MLP().cuda()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:46:02.253871Z","iopub.execute_input":"2021-05-22T11:46:02.254213Z","iopub.status.idle":"2021-05-22T11:46:02.268121Z","shell.execute_reply.started":"2021-05-22T11:46:02.254177Z","shell.execute_reply":"2021-05-22T11:46:02.267412Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**DATA PROCESSING METHODS**","metadata":{}},{"cell_type":"code","source":"def normalize(data):\n    return (data - np.mean(data, axis=0))/np.std(data, axis=0)\n\naudio_train = normalize(audio_train)\naudio_val = normalize(audio_val)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:46:03.271951Z","iopub.execute_input":"2021-05-22T11:46:03.272261Z","iopub.status.idle":"2021-05-22T11:46:03.283988Z","shell.execute_reply.started":"2021-05-22T11:46:03.272234Z","shell.execute_reply":"2021-05-22T11:46:03.282997Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class AddGaussianNoise:\n    def __init__(self, mean=0., std=1.):\n        self.std = std\n        self.mean = mean\n        \n    def __call__(self, tensor):\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n    \n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:46:03.757037Z","iopub.execute_input":"2021-05-22T11:46:03.757347Z","iopub.status.idle":"2021-05-22T11:46:03.763016Z","shell.execute_reply.started":"2021-05-22T11:46:03.757317Z","shell.execute_reply":"2021-05-22T11:46:03.761858Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class RandomCircularShift:      \n    def __call__(self, tensor):\n        return torch.roll(tensor, 13*np.random.randint(8),dims=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:46:04.202935Z","iopub.execute_input":"2021-05-22T11:46:04.203248Z","iopub.status.idle":"2021-05-22T11:46:04.207537Z","shell.execute_reply.started":"2021-05-22T11:46:04.203219Z","shell.execute_reply":"2021-05-22T11:46:04.206555Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"**AUDIO DATA TRANSFORMATION** ","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\naudio_train_transform = transforms.Compose([\n    AddGaussianNoise(0.0, 0.1),\n    RandomCircularShift()\n])\n\naudio_val_transform = transforms.Compose([\n    AddGaussianNoise(0.0, 0.1),\n    RandomCircularShift()\n])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:48:37.217412Z","iopub.execute_input":"2021-05-22T11:48:37.217750Z","iopub.status.idle":"2021-05-22T11:48:37.221966Z","shell.execute_reply.started":"2021-05-22T11:48:37.217720Z","shell.execute_reply":"2021-05-22T11:48:37.221133Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"**AUDIO DATA LOADER**","metadata":{}},{"cell_type":"code","source":"data_type = 'audio'\ntrain_data = CustomDataset(data_type=data_type, root_dir='/data', img_data=img_train, audio_data=audio_train, labels=labels_train, audio_transform=audio_train_transform)\nval_data = CustomDataset(data_type=data_type, root_dir='/data', img_data=img_val, audio_data=audio_val, labels=labels_val, audio_transform=audio_val_transform)\n\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:48:39.294676Z","iopub.execute_input":"2021-05-22T11:48:39.295343Z","iopub.status.idle":"2021-05-22T11:48:39.306509Z","shell.execute_reply.started":"2021-05-22T11:48:39.295304Z","shell.execute_reply":"2021-05-22T11:48:39.305703Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(resnext.fc.parameters(), lr=0.001) \ncriterion = nn.CrossEntropyLoss()\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=0,factor=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:48:42.090105Z","iopub.execute_input":"2021-05-22T11:48:42.090418Z","iopub.status.idle":"2021-05-22T11:48:42.096418Z","shell.execute_reply.started":"2021-05-22T11:48:42.090391Z","shell.execute_reply":"2021-05-22T11:48:42.095296Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"epochs = 30\nresnext, loss_vals, train_acc_vals, val_acc_vals = train(resnext, train_loader, val_loader, criterion, optimizer, scheduler, epochs)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:48:42.876505Z","iopub.execute_input":"2021-05-22T11:48:42.876854Z","iopub.status.idle":"2021-05-22T11:48:42.901971Z","shell.execute_reply.started":"2021-05-22T11:48:42.876819Z","shell.execute_reply":"2021-05-22T11:48:42.900389Z"},"trusted":true},"execution_count":36,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-f5d89a70ffbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-f40ec88a1eef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, model, criterion, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainloader :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nval_loader :\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mval_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'ResNet' object is not subscriptable"],"ename":"TypeError","evalue":"'ResNet' object is not subscriptable","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}